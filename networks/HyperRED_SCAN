import os
os.environ["KMP_DUPLICATE_LIB_OK"]="TRUE" 
import torch
import torch.nn as nn
from torchsummary import summary
import torch.nn.functional as F

class RED_CNN_Geo_VAE(nn.Module):
    def __init__(self, out_ch=96):
        super(RED_CNN_Geo_VAE, self).__init__()
        self.Geo_HypNet = Geo_HypNet()

        self.conv1 = nn.Conv2d(1, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv3 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv4 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv5 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)

        self.tconv1 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv2 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv3 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv4 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv5 = nn.ConvTranspose2d(out_ch, 1, kernel_size=5, stride=1, padding=0)

        self.relu = nn.ReLU()

    def forward(self, x, feature_vec):
        gamma, beta, decoded = self.Geo_HypNet(feature_vec)

        ## encoder
        en_gamma1 = gamma[:,0:96].view(x.size(0), 96, 1, 1)
        en_beta1 = beta[:,0:96].view(x.size(0), 96, 1, 1)
        
        en_gamma2 = gamma[:,96:192].view(x.size(0), 96, 1, 1)
        en_beta2 = beta[:,96:192].view(x.size(0), 96, 1, 1)

        en_gamma3 = gamma[:,192:288].view(x.size(0), 96, 1, 1)
        en_beta3 = beta[:,192:288].view(x.size(0), 96, 1, 1)

        en_gamma4 = gamma[:,288:384].view(x.size(0), 96, 1, 1)
        en_beta4 = beta[:,288:384].view(x.size(0), 96, 1, 1)

        en_gamma5 = gamma[:,384:480].view(x.size(0), 96, 1, 1)
        en_beta5 = beta[:,384:480].view(x.size(0), 96, 1, 1)

        ## decoder
        de_gamma1 = gamma[:,480:576].view(x.size(0), 96, 1, 1)
        de_beta1 = beta[:,480:576].view(x.size(0), 96, 1, 1)
        
        de_gamma2 = gamma[:,576:672].view(x.size(0), 96, 1, 1)
        de_beta2 = beta[:,576:672].view(x.size(0), 96, 1, 1)

        de_gamma3 = gamma[:,672:768].view(x.size(0), 96, 1, 1)
        de_beta3 = beta[:,672:768].view(x.size(0), 96, 1, 1)

        de_gamma4 = gamma[:,768:864].view(x.size(0), 96, 1, 1)
        de_beta4 = beta[:,768:864].view(x.size(0), 96, 1, 1)

        ## last
        last_gamma = gamma[:,864].view(x.size(0), 1, 1, 1)
        last_beta = beta[:,864].view(x.size(0), 1, 1, 1)

        # encoder
        residual_1 = x
        out = self.conv1(x)
        out = en_gamma1 * out + en_beta1
        out = self.relu(out)

        out = self.conv2(out)
        out = en_gamma2 * out + en_beta2
        out = self.relu(out)
        residual_2 = out

        out = self.conv3(out)
        out = en_gamma3 * out + en_beta3
        out = self.relu(out)

        out = self.conv4(out)
        out = en_gamma4 * out + en_beta4
        out = self.relu(out)
        residual_3 = out

        out = self.conv5(out)
        out = en_gamma5 * out + en_beta5
        out = self.relu(out)

        # decoder
        ####这里改了，提取多个输出
        out = self.tconv1(out)
        out = de_gamma1 * out + de_beta1
        out += residual_3

        out = self.tconv2(self.relu(out))
        out = de_gamma2 * out + de_beta2

        out = self.tconv3(self.relu(out))
        out = de_gamma3 * out + de_beta3
        out += residual_2

        out = self.tconv4(self.relu(out))
        out = de_gamma4 * out + de_beta4
        out = self.tconv5(self.relu(out))
        out = last_gamma * out + last_beta

        out += residual_1
        out = self.relu(out)
        # return out, gamma, beta, decoded
        return out, decoded


class RED_CNN_Geo_VAE_2bn(nn.Module):
    def __init__(self, out_ch=96):
        super(RED_CNN_Geo_VAE_2bn, self).__init__()
        self.Geo_HypNet = Geo_HypNet_two_bn()

        self.conv1 = nn.Conv2d(1, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv3 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv4 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv5 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)

        self.tconv1 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv2 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv3 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv4 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv5 = nn.ConvTranspose2d(out_ch, 1, kernel_size=5, stride=1, padding=0)

        self.relu = nn.ReLU()

    def forward(self, x, feature_vec):
        gamma, beta, decoded = self.Geo_HypNet(feature_vec)
        gamma0 = gamma[:,0:96].view(x.size(0), 96, 1, 1)
        beta0 = beta[:,0:96].view(x.size(0), 96, 1, 1)
        gamma1 = gamma[:,96:192].view(x.size(0), 96, 1, 1)
        beta1 = beta[:,96:192].view(x.size(0), 96, 1, 1)
        gamma2 = gamma[:,192].view(x.size(0), 1, 1, 1)
        beta2 = beta[:,192].view(x.size(0), 1, 1, 1)
        # encoder
        residual_1 = x
        out = self.conv1(x)
        out = gamma0 * out + beta0
        out = self.relu(out)

        out = self.conv2(out)
        out = gamma0 * out + beta0
        out = self.relu(out)
        residual_2 = out

        out = self.conv3(out)
        out = gamma0 * out + beta0
        out = self.relu(out)

        out = self.conv4(out)
        out = gamma0 * out + beta0
        out = self.relu(out)
        residual_3 = out

        out = self.conv5(out)
        out = gamma0 * out + beta0
        out = self.relu(out)

        # decoder
        ####这里改了，提取多个输出
        out = self.tconv1(out)
        out = gamma1 * out + beta1
        out += residual_3

        out = self.tconv2(self.relu(out))
        out = gamma1 * out + beta1
        out = self.tconv3(self.relu(out))
        out = gamma1 * out + beta1
        out += residual_2

        out = self.tconv4(self.relu(out))
        out = gamma1 * out + beta1
        out = self.tconv5(self.relu(out))
        out = gamma2 * out + beta2

        out += residual_1
        out = self.relu(out)
        
        # return out, gamma, beta, decoded
        return out, decoded


class Geo_HypNet(nn.Module):
    def __init__(self):
        super(Geo_HypNet, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(7, 256, bias=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.Linear(256, 512, bias=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False)
        )

        # self.wei = nn.Linear(512, 193, bias=False)  # -> mean var  wei bias  b,2,dim
        self.wei = nn.Linear(512, 96*9+1, bias=False)  # mean ?

        self.bias = nn.Linear(512, 96*9+1, bias=False)

        self.decoder = nn.Sequential(
            nn.Linear(96*9+1,512,bias = True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.Linear(512, 256, bias=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.ReLU(inplace=True),
            nn.Linear(256, 7, bias=True),
        )


    def forward_(self, x):
        out = self.encoder(x)
        out1 = self.wei(out)
        out2 = self.bias(out)
        # print(out.shape)

        code = torch.cat((out1,out2),dim=1)
        out = self.decoder(code)
        return out1, out2, out

    def forward(self, x):
        enc = self.encoder(x)  # output of encoder

        gamma = self.wei(enc)  # gamma for denoising-net modulation
        beta = self.bias(enc)  # beta for denoising-net modulation

        log_var = torch.exp(0.5 * gamma)  # std for VAE
        mu = beta  #  mu for VAE

        # split the modulation layer into encoder-decoder, shape: [batch_size, layer_num=?, dim=96]
        # std = torch.exp(0.5 * torch.reshape(gamma, (ba,9,96)))
        # mu = torch.reshape(gamma, (ba,9,96))

        feat = torch.randn_like(log_var) * log_var + mu  # reparameterize process, very simple, aims to caculate and backward gradiant
        recon = self.decoder(feat)  # reconstructed data for VAE. Conduct reconstruction loss (MSE)
        return gamma, beta, recon


class Geo_HypNet_two_bn(nn.Module):
    def __init__(self):
        super(Geo_HypNet_two_bn, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(7, 256, bias=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.Linear(256, 512, bias=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False)
        )

        # self.wei = nn.Linear(512, 193, bias=False)  # -> mean var  wei bias  b,2,dim
        self.wei = nn.Linear(512, 193, bias=False)  # mean ?

        self.bias = nn.Linear(512, 193, bias=False)

        self.decoder = nn.Sequential(
            nn.Linear(193,512,bias = True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.Linear(512, 256, bias=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.ReLU(inplace=True),
            nn.Linear(256, 7, bias=True),
        )


    def forward_(self, x):
        out = self.encoder(x)
        out1 = self.wei(out)
        out2 = self.bias(out)
        # print(out.shape)

        code = torch.cat((out1,out2),dim=1)
        out = self.decoder(code)
        return out1, out2, out

    def forward(self, x):
        enc = self.encoder(x)  # output of encoder

        gamma = self.wei(enc)  # gamma for denoising-net modulation
        beta = self.bias(enc)  # beta for denoising-net modulation

        log_var = torch.exp(0.5 * gamma)  # std for VAE
        mu = beta  #  mu for VAE

        # split the modulation layer into encoder-decoder, shape: [batch_size, layer_num=?, dim=96]
        # std = torch.exp(0.5 * torch.reshape(gamma, (ba,9,96)))
        # mu = torch.reshape(gamma, (ba,9,96))

        feat = torch.randn_like(log_var) * log_var + mu  # reparameterize process, very simple, aims to caculate and backward gradiant
        recon = self.decoder(feat)  # reconstructed data for VAE. Conduct reconstruction loss (MSE)
        return gamma, beta, recon


# loss sample
def loss_sample_code():
    hyper_net = None  # hyper net
    denose_net = None  # denoising net (RED-CNN)
    geo_param = None  # measurement params
    # vae
    gamma, beta, recon = hyper_net(geo_param)

    recon_loss = mse_loss(geo_param, recon)  # conduct reconstruction loss

    log_var = torch.exp(0.5 * gamma)
    mu = beta

    k_loss = kld_loss(log_var, mu)

    vae_loss = recon_loss + 0.1 * k_loss  # 0.1, 0.01 , ...

def kld_loss(log_var, mu):
    # first, compute sum loss on feat dim (=(1,2,...)), then compute mean loss on BATCH dim
    return torch.mean(-0.5 * torch.sum(1 + log_var - mu ** 2 - log_var.exp(), dim=1), dim=0)




class Ana_Hyper(nn.Module):
    def __init__(self, input_dim, hidden_dim, output_dim, num_heads=4):
        super(Ana_Hyper, self).__init__()
        
        self.avg_pool = nn.AvgPool1d(kernel_size=4, stride=4)
        output_dim = 3481
        self.projection = nn.Linear(input_dim//4, hidden_dim)
        self.attention = nn.MultiheadAttention(embed_dim=hidden_dim, num_heads=num_heads)
        self.output_layer = nn.Linear(hidden_dim, output_dim)

# self.ana_model = Ana_Hyper(input_dim=32000,hidden_dim=2048,output_dim = 13924)

    def forward(self, x):

        x = self.avg_pool(x)
        x_proj = self.projection(x)  
        x_proj = x_proj.permute(1, 0, 2) 
        attn_output, _ = self.attention(x_proj, x_proj, x_proj)
        attn_output = attn_output.permute(1, 0, 2)  
        output = self.output_layer(attn_output)  
        return output

class Geo_HyperNet_192(nn.Module):
    def __init__(self):
        super(Geo_HyperNet_192, self).__init__()
        self.encoder = nn.Sequential(
            nn.Linear(7, 256, bias=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False),
            nn.Linear(256, 128, bias=True),
            nn.ReLU(inplace=True),
            nn.Dropout(p=0.5, inplace=False)
        )

        self.wei = nn.Linear(128, 96, bias=False)  # -> mean var  wei bias  b,2,dim
        # self.wei = nn.Linear(192, 92, bias=False)  # mean ?

        self.bias = nn.Linear(128, 96, bias=False)

        # self.decoder = nn.Sequential(
        #     nn.Linear(192,512,bias = True),
        #     nn.ReLU(inplace=True),
        #     nn.Dropout(p=0.5, inplace=False),
        #     nn.Linear(512, 256, bias=True),
        #     nn.Dropout(p=0.5, inplace=False),
        #     nn.ReLU(inplace=True),
        #     nn.Linear(256, 7, bias=True),
        # )


    def forward(self, x):
        out = self.encoder(x)
        out1 = self.wei(out)
        out2 = self.bias(out)
        # print(out.shape)

        # code = torch.cat((out1,out2),dim=1)
        # out = self.decoder(code)
        return out1, out2, out


class SELayer(nn.Module):
    def __init__(self, channel, reduction=4):
        super(SELayer, self).__init__()
        self.avg_pool = nn.AdaptiveAvgPool2d(1)
        self.fc = nn.Sequential(
            nn.Linear(channel, channel // reduction, bias=False),
            nn.ReLU(inplace=True),
            nn.Linear(channel // reduction, channel, bias=False),
            nn.Sigmoid()
        )

    def forward(self, x):
        b, c, _, _ = x.size()
        y = self.avg_pool(x).view(b, c)
        y = self.fc(y).view(b, c, 1, 1)
        # return x * y.expand_as(x)
        return y


class Adapter(nn.Module):
    def __init__(self) -> None:
        super().__init__()
        self.se1_alpha = SELayer(channel=96)
        # self.se1_beta = SELayer(channel=92)

        self.se2_alpha = SELayer(channel=96)
        # self.se2_beta = SELayer(channel=92)

        # self.fuse_1 = AttentionFusion(dim=96)
        # self.fuse_2 = AttentionFusion(dim=96)
        self.se1_1 = SELayer(channel=2)
        self.se2_2 = SELayer(channel=2)

        self.act = nn.Sigmoid()

    def forward(self, res_fe_1, res_fe_2, geo_alpha):
        
        geo_alpha = self.act(geo_alpha)

        se1_alpha = self.se1_alpha(res_fe_1)
        se2_alpha = self.se2_alpha(res_fe_2)
        # b,c,w,h = se1_alpha.size()
        # se1 = torch.cat((se1_alpha,geo_alpha),dim=1)
        # se2 = torch.cat((se2_alpha,geo_alpha),dim=1)
        se1 = torch.cat((se1_alpha,geo_alpha),dim=2).permute(0, 2, 1, 3)
        # se1 = se1_alpha + geo_alpha
        att1 = self.se1_1(se1)
        weight1, weight2 = att1[:, 0:1, :, :], att1[:, 1:2, :, :]
        fuse_att1 = weight1 * se1_alpha + weight2 * geo_alpha

        se2 = torch.cat((se2_alpha,geo_alpha),dim=2).permute(0, 2, 1, 3) 
        att2 = self.se2_2(se2)
        weight2_1, weight2_2 = att2[:, 0:1, :, :], att2[:, 1:2, :, :]
        fuse_att2 = weight2_1 * se1_alpha + weight2_2 * geo_alpha        

        res_fe_1 = res_fe_1 + res_fe_1 * fuse_att1
        res_fe_2 = res_fe_2 + res_fe_2 * fuse_att2


        return res_fe_1, res_fe_2


class RED_CNN_NOHYP(nn.Module):
    def __init__(self, out_ch=96):
        super(RED_CNN_NOHYP, self).__init__()
        # self.Geo_HypNet = Geo_HypNet_two_bn()
        self.geo_model = Geo_HyperNet_192()
        self.ana_model = Ana_Hyper(input_dim=32000,hidden_dim=2048,output_dim = 13924)

        # self.adapter = Adapter()

        self.conv1 = nn.Conv2d(1, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv2 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv3 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv4 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.conv5 = nn.Conv2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)

        self.tconv1 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv2 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv3 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv4 = nn.ConvTranspose2d(out_ch, out_ch, kernel_size=5, stride=1, padding=0)
        self.tconv5 = nn.ConvTranspose2d(out_ch, 1, kernel_size=5, stride=1, padding=0)

        self.relu = nn.ReLU()
        self.upsample = nn.Upsample(size=(236, 236), mode='bilinear', align_corners=False)

    def forward(self, x, feature_vec, ana_data):
        
        gamma, beta, decoded= self.geo_model(feature_vec)

        spa_fea = self.ana_model(ana_data)
        bn_size = ana_data.shape[0]
        reshaped_anto_fe = spa_fea.view(bn_size, 1, 59, 59)    
        reshaped_anto_fe = self.upsample(reshaped_anto_fe)

        gamma = gamma.view(bn_size,96,1,1)
        beta = beta.view(bn_size,96,1,1)

         # encoder
        residual_1 = x
        out = self.conv1(x)
        # out = gamma0 * out + beta0
        out = self.relu(out)

        out = self.conv2(out)
        # out = gamma0 * out + beta0
        out = self.relu(out)
        residual_2 = out

        out = self.conv3(out)
        # out = gamma0 * out + beta0
        out = self.relu(out)

        out = self.conv4(out)
        # out = gamma0 * out + beta0
        out = self.relu(out)
        residual_3 = out

        out = self.conv5(out)
        out = gamma * out + beta
        code = self.relu(out)

        # residual_2, residual_3 = self.adapter(residual_2, residual_3, gamma)

        # expanded_weight_matrix = spa_fea.repeat_interleave(2, dim=0).repeat_interleave(2, dim=1)
        
        out = code * 0.9 + code * reshaped_anto_fe * 0.1

        # decoder
        out = self.tconv1(out)
        # out = gamma1 * out + beta1
        out += residual_3

        out = self.tconv2(self.relu(out))
        # out = gamma2 * out + beta2

        out = self.tconv3(self.relu(out))
        # out = gamma3 * out + beta3
        out += residual_2

        out = self.tconv4(self.relu(out))
        # out = gamma4 * out + beta4
        out = self.tconv5(self.relu(out))
        # out = gamma5 * out + beta5

        out += residual_1
        out = self.relu(out)
        # if mode == 'train':
        #     return out, code, gamma, beta, decoded
        # else:
        # if mode == 'train':
        #     return out,code,gamma,beta
        
        # return out, code
        return out, decoded


if __name__ == '__main__':


    net = RED_CNN_NOHYP()
    ana_fe = torch.randn(20,1,32000)
    fea_inp = torch.randn(20,7)
    inp = torch.randn(20,1,256,256)
    out = net(inp,fea_inp,ana_fe)
    for key in net.state_dict().keys():

    print('1')
